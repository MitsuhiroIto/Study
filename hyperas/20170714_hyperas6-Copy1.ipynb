{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperasの練習\n",
    "\n",
    "*20170715 Mitsuhiro Ito*\n",
    "\n",
    "\n",
    "* (https://github.com/maxpumperla/hyperas/tree/master/examples)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from utils import save_model_viz, save_weights, save_hist, plot_hist\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import uniform, choice, conditional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    train_gan = ImageDataGenerator(rescale=1.0 / 255,\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    valid_gan = ImageDataGenerator(rescale=1.0 / 255,\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    train_generator = train_gan.flow_from_directory('/home/dl/mitsu-work/data/train/',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "    valid_generator = valid_gan.flow_from_directory('/home/dl/mitsu-work/data/valid/',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train_generator, valid_generator):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), input_shape=(150, 150, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr={{choice([0.001, 0.0005, 0.0001])}}, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    " \n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    batch_size = 16\n",
    "    \n",
    "              \n",
    "\n",
    " \n",
    "    model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = 2000 // batch_size, \n",
    "                    epochs=20, \n",
    "                    verbose=1, \n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps= 800 // batch_size)\n",
    "    \n",
    "    \n",
    "    score, acc = model.evaluate_generator(generator=valid_generator, \n",
    "                                      steps= 800 // batch_size)\n",
    "    \n",
    "    print(score, acc)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 108)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/dl/.pyenv/versions/3.5.2/lib/python3.5/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2862\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-5-bd260f2ddd61>\"\u001b[0m, line \u001b[1;32m8\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    notebook_name='20170714_hyperas6' )\n",
      "  File \u001b[1;32m\"/home/dl/.pyenv/versions/3.5.2/lib/python3.5/site-packages/hyperas/optim.py\"\u001b[0m, line \u001b[1;32m67\u001b[0m, in \u001b[1;35mminimize\u001b[0m\n    verbose=verbose)\n",
      "  File \u001b[1;32m\"/home/dl/.pyenv/versions/3.5.2/lib/python3.5/site-packages/hyperas/optim.py\"\u001b[0m, line \u001b[1;32m96\u001b[0m, in \u001b[1;35mbase_minimizer\u001b[0m\n    model_str = get_hyperopt_model_string(model, data, functions, notebook_name, verbose, stack)\n",
      "  File \u001b[1;32m\"/home/dl/.pyenv/versions/3.5.2/lib/python3.5/site-packages/hyperas/optim.py\"\u001b[0m, line \u001b[1;32m182\u001b[0m, in \u001b[1;35mget_hyperopt_model_string\u001b[0m\n    imports = extract_imports(cleaned_source, verbose)\n",
      "  File \u001b[1;32m\"/home/dl/.pyenv/versions/3.5.2/lib/python3.5/site-packages/hyperas/utils.py\"\u001b[0m, line \u001b[1;32m40\u001b[0m, in \u001b[1;35mextract_imports\u001b[0m\n    tree = ast.parse(source)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/dl/.pyenv/versions/3.5.2/lib/python3.5/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m108\u001b[0m\n\u001b[0;31m    model.add(Dense(1))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_generator, valid_generator = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=10,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='20170714_hyperas6' )\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate_generator(valid_generator, steps=64))\n",
    "print(best_run)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
